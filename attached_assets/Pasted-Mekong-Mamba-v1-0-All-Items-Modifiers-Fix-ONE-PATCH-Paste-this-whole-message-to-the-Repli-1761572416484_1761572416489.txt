Mekong Mamba v1.0 — “All Items + Modifiers” Fix (ONE PATCH)

> Paste this whole message to the Replit agent. Do steps 1→8 in order.



1) Migrations — schema you can trust (idempotent)

Create and run: server/migrations/2025-10-27_mm_all_items.sql

-- Core alias (if not already)
CREATE TABLE IF NOT EXISTS item_alias (
  alias_name  text PRIMARY KEY,           -- exact receipt line name
  sku         text NOT NULL               -- resolves to catalog SKU
);

-- Catalog extensions: meal-deals, and ensure essentials exist
ALTER TABLE item_catalog
  ADD COLUMN IF NOT EXISTS is_meal_set boolean NOT NULL DEFAULT false,
  ADD COLUMN IF NOT EXISTS base_sku   text NULL;

-- Known meal-deal -> base SKU links (verify)
UPDATE item_catalog SET is_meal_set=true, base_sku='10019' WHERE sku='10036'; -- Super Double Set -> Super Double
UPDATE item_catalog SET is_meal_set=true, base_sku='10004' WHERE sku='10033'; -- Single Set  -> Single
UPDATE item_catalog SET is_meal_set=true, base_sku='10009' WHERE sku='10034'; -- Triple Set  -> Triple
UPDATE item_catalog SET is_meal_set=true, base_sku='10006' WHERE sku='10032'; -- Double Set  -> Ultimate Double
UPDATE item_catalog SET is_meal_set=true, base_sku='10070' WHERE sku='10071'; -- Karaage Meal -> Karaage Burger
-- Mix & Match is a generic bundle, do not map to a base burger:
UPDATE item_catalog SET is_meal_set=true, base_sku=NULL   WHERE sku='10069';

-- Normalized receipts: helpful indexes (safe if they exist)
CREATE INDEX IF NOT EXISTS ix_lv_receipt_bkk ON lv_receipt(datetime_bkk);
CREATE INDEX IF NOT EXISTS ix_lv_line_item_sku ON lv_line_item(sku);
CREATE INDEX IF NOT EXISTS ix_lv_line_item_receipt ON lv_line_item(receipt_id);

-- Modifiers table (per LOYVERSE line modifiers), if not present
-- Expected columns: receipt_id, parent_line_no, name, sku (nullable), qty, unit_price
-- If your table already exists with different names, adapt the views below instead of creating.
CREATE TABLE IF NOT EXISTS lv_modifier (
  receipt_id   text NOT NULL,
  parent_line_no int NOT NULL,
  name         text NOT NULL,
  sku          text NULL,
  qty          numeric NOT NULL DEFAULT 1,
  unit_price   numeric NULL,
  PRIMARY KEY (receipt_id, parent_line_no, name)
);

-- Analytics tables for modifiers
CREATE TABLE IF NOT EXISTS analytics_shift_modifier (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  shift_date date NOT NULL,
  from_ts timestamptz NOT NULL,
  to_ts timestamptz NOT NULL,
  sku text NULL,
  name text NOT NULL,
  category text NOT NULL DEFAULT 'modifier',
  qty integer NOT NULL,
  raw_hits jsonb NOT NULL DEFAULT '[]'::jsonb,
  updated_at timestamptz NOT NULL DEFAULT now(),
  UNIQUE (shift_date, COALESCE(sku, name))
);

Run:

psql "$DATABASE_URL" -f server/migrations/2025-10-27_mm_all_items.sql


---

2) Time window util (5pm→3am Bangkok), single source of truth

File: server/services/time/shiftWindow.ts

import { DateTime } from "luxon";
export function shiftWindow(dateISO: string) {
  const base = DateTime.fromISO(dateISO, { zone: "Asia/Bangkok" }).startOf("day");
  const from = base.plus({ hours: 17 });         // 17:00
  const to   = base.plus({ days: 1, hours: 3 }); // +1 day, 03:00
  return { shiftDate: base.toISODate()!, fromISO: from.toISO()!, toISO: to.toISO()! };
}

Make sure every shift endpoint imports and uses this.


---

3) Computation service — SKU-first, sets deduped, modifiers captured

Edit/replace: server/services/shiftItems.ts (core logic)

import { PrismaClient } from '@prisma/client';
import { shiftWindow } from './time/shiftWindow';
const db = new PrismaClient();
const BEEF_G = 95;

export async function computeShiftAll(dateISO: string) {
  const { shiftDate, fromISO, toISO } = shiftWindow(dateISO);

  // 1) Find receipts that have meal-sets in the window
  const mealSetReceipts = await db.$queryRaw<{receipt_id:string}[]>`
    WITH win AS (SELECT ${fromISO}::timestamptz AS from_ts, ${toISO}::timestamptz AS to_ts)
    SELECT DISTINCT li.receipt_id
    FROM lv_line_item li
    JOIN lv_receipt r ON r.receipt_id = li.receipt_id, win
    JOIN item_catalog c ON c.sku = li.sku
    WHERE r.datetime_bkk >= win.from_ts AND r.datetime_bkk < win.to_ts
      AND c.is_meal_set = true
  `;
  const setReceiptIds = new Set(mealSetReceipts.map(r=>r.receipt_id));

  // 2) Base exclusions: base burger zero-price components when paired with a set on SAME receipt
  const exclusions = await db.$queryRaw<{receipt_id:string; line_no:number}[]>`
    WITH win AS (SELECT ${fromISO}::timestamptz AS from_ts, ${toISO}::timestamptz AS to_ts)
    SELECT li.receipt_id, li.line_no
    FROM lv_line_item li
    JOIN lv_receipt r ON r.receipt_id = li.receipt_id, win
    JOIN item_catalog b ON b.sku = li.sku
    WHERE r.datetime_bkk >= win.from_ts AND r.datetime_bkk < win.to_ts
      AND b.category='burger'
      AND COALESCE(li.unit_price,0)=0
      AND EXISTS (
        SELECT 1
        FROM lv_line_item si
        JOIN item_catalog mc ON mc.sku = si.sku
        WHERE si.receipt_id = li.receipt_id
          AND mc.is_meal_set = true
          AND mc.base_sku = li.sku
      )
  `;
  const excludeKey = new Set(exclusions.map(e=>`${e.receipt_id}#${e.line_no}`));

  // 3) Line items (all categories), SKU-first with alias fallback ONLY when sku is NULL
  const lineItems = await db.$queryRaw<{ sku:string|null; name:string; qty:number; receipt_id:string; line_no:number }[]>`
    WITH win AS (SELECT ${fromISO}::timestamptz AS from_ts, ${toISO}::timestamptz AS to_ts)
    SELECT COALESCE(li.sku, ia.sku) AS sku,
           li.name,
           SUM(li.qty)::int AS qty,
           li.receipt_id,
           MIN(li.line_no)::int AS line_no
    FROM lv_line_item li
    JOIN lv_receipt r ON r.receipt_id = li.receipt_id, win
    LEFT JOIN item_alias ia ON li.sku IS NULL AND ia.alias_name = li.name
    WHERE r.datetime_bkk >= win.from_ts AND r.datetime_bkk < win.to_ts
    GROUP BY COALESCE(li.sku, ia.sku), li.name, li.receipt_id
  `;

  // 4) Modifiers (group by resolved sku/name), keep them separate in analytics_shift_modifier
  const modifiers = await db.$queryRaw<{ sku:string|null; name:string; qty:number; receipt_id:string }[]>`
    WITH win AS (SELECT ${fromISO}::timestamptz AS from_ts, ${toISO}::timestamptz AS to_ts)
    SELECT COALESCE(m.sku, ia.sku) AS sku,
           m.name,
           SUM(m.qty)::int AS qty,
           m.receipt_id
    FROM lv_modifier m
    JOIN lv_receipt r ON r.receipt_id = m.receipt_id, win
    LEFT JOIN item_alias ia ON m.sku IS NULL AND ia.alias_name = m.name
    WHERE r.datetime_bkk >= win.from_ts AND r.datetime_bkk < win.to_ts
    GROUP BY COALESCE(m.sku, ia.sku), m.name, m.receipt_id
  `;

  // 5) Load active catalog
  const catalog = await db.$queryRaw<{
    sku:string; name:string; category:string; kind:string|null; patties_per:number|null; grams_per:number|null; rolls_per:number|null; is_meal_set:boolean; base_sku:string|null;
  }[]>`SELECT sku, name, category, kind, patties_per, grams_per, rolls_per, is_meal_set, base_sku
       FROM item_catalog WHERE active=true`;

  const bySku = new Map(catalog.map(c => [c.sku, c]));

  // 6) Aggregate ITEMS with exclusions
  const accItems = new Map<string, {
    sku:string|null; name:string; category:string; qty:number; patties:number; red:number; chick:number; rolls:number; hits:Set<string>;
  }>();

  for (const r of lineItems) {
    // Skip base burger component lines when excluded
    if (excludeKey.has(`${r.receipt_id}#${r.line_no}`)) continue;

    const rule = r.sku ? bySku.get(r.sku) ?? null : null;
    const name = rule?.name ?? r.name;
    const category = rule?.category ?? 'other';

    const key = r.sku ?? name;
    if (!accItems.has(key)) accItems.set(key, { sku:r.sku, name, category, qty:0, patties:0, red:0, chick:0, rolls:0, hits:new Set() });
    const p = accItems.get(key)!;
    p.qty += r.qty;
    p.hits.add(`${r.sku ?? 'no-sku'} :: ${name}`);

    if (category === 'burger' && rule) {
      if (rule.kind === 'beef') {
        const patties = (rule.patties_per ?? 1) * r.qty;
        p.patties += patties;
        p.red += patties * BEEF_G;
      } else if (rule.kind === 'chicken') {
        p.chick += (rule.grams_per ?? 100) * r.qty;
      }
      p.rolls += (rule.rolls_per ?? 1) * r.qty;
    }
  }

  // 7) Aggregate MODIFIERS separately
  const accMods = new Map<string, { sku:string|null; name:string; category:string; qty:number; hits:Set<string> }>();
  for (const m of modifiers) {
    const rule = m.sku ? bySku.get(m.sku) ?? null : null;
    const name = rule?.name ?? m.name;
    const key = m.sku ?? name;
    if (!accMods.has(key)) accMods.set(key, { sku:m.sku, name, category:'modifier', qty:0, hits:new Set() });
    const p = accMods.get(key)!;
    p.qty += m.qty;
    p.hits.add(`${m.sku ?? 'no-sku'} :: ${name}`);
  }

  // 8) Write cache transactionally (items + modifiers + category rollups)
  await db.$transaction(async tx => {
    await tx.$executeRaw`DELETE FROM analytics_shift_item WHERE shift_date=${shiftDate}::date`;
    await tx.$executeRaw`DELETE FROM analytics_shift_modifier WHERE shift_date=${shiftDate}::date`;
    await tx.$executeRaw`DELETE FROM analytics_shift_category_summary WHERE shift_date=${shiftDate}::date`;

    const byCat:any = {};

    for (const v of accItems.values()) {
      byCat[v.category] = (byCat[v.category] ?? 0) + v.qty;
      await tx.$executeRaw`
        INSERT INTO analytics_shift_item
          (shift_date, from_ts, to_ts, sku, name, category, qty, patties, red_meat_g, chicken_g, rolls, raw_hits, updated_at)
        VALUES
          (${shiftDate}::date, ${fromISO}::timestamptz, ${toISO}::timestamptz,
           ${v.sku}, ${v.name}, ${v.category}, ${v.qty}, ${v.patties}, ${v.red}, ${v.chick}, ${v.rolls},
           ${JSON.stringify(Array.from(v.hits))}::jsonb, now())
        ON CONFLICT (shift_date, COALESCE(sku, name)) DO UPDATE
          SET qty=EXCLUDED.qty, patties=EXCLUDED.patties, red_meat_g=EXCLUDED.red_meat_g,
              chicken_g=EXCLUDED.chicken_g, rolls=EXCLUDED.rolls, raw_hits=EXCLUDED.raw_hits,
              from_ts=EXCLUDED.from_ts, to_ts=EXCLUDED.to_ts, updated_at=now()
      `;
    }

    // modifiers table
    for (const v of accMods.values()) {
      byCat['modifier'] = (byCat['modifier'] ?? 0) + v.qty;
      await tx.$executeRaw`
        INSERT INTO analytics_shift_modifier
          (shift_date, from_ts, to_ts, sku, name, category, qty, raw_hits, updated_at)
        VALUES
          (${shiftDate}::date, ${fromISO}::timestamptz, ${toISO}::timestamptz,
           ${v.sku}, ${v.name}, 'modifier', ${v.qty}, ${JSON.stringify(Array.from(v.hits))}::jsonb, now())
        ON CONFLICT (shift_date, COALESCE(sku, name)) DO UPDATE
          SET qty=EXCLUDED.qty, raw_hits=EXCLUDED.raw_hits,
              from_ts=EXCLUDED.from_ts, to_ts=EXCLUDED.to_ts, updated_at=now()
      `;
    }

    // category summaries
    for (const [cat,total] of Object.entries(byCat)) {
      await tx.$executeRaw`
        INSERT INTO analytics_shift_category_summary
          (shift_date, from_ts, to_ts, category, items_total, updated_at)
        VALUES
          (${shiftDate}::date, ${fromISO}::timestamptz, ${toISO}::timestamptz, ${cat}, ${total}, now())
        ON CONFLICT (shift_date, category) DO UPDATE
          SET items_total=EXCLUDED.items_total, from_ts=EXCLUDED.from_ts, to_ts=EXCLUDED.to_ts, updated_at=now()
      `;
    }
  });

  // 9) Response (items only; modifiers can be separate endpoint if preferred)
  const items = Array.from(accItems.values()).sort((a,b)=>
    a.category===b.category ? a.name.localeCompare(b.name) : a.category.localeCompare(b.category)
  ).map(v=>({
    sku:v.sku, name:v.name, category:v.category, qty:v.qty,
    patties:v.patties, redMeatGrams:v.red, chickenGrams:v.chick, rolls:v.rolls
  }));

  return { shiftDate, fromISO, toISO, items, sourceUsed:'live' as const };
}

> Why this works:
• Counts by SKU first (alias only if SKU is null).
• Excludes base burger zero-price component lines whenever a meal-set exists on that receipt.
• Modifiers captured into analytics_shift_modifier without contaminating item counts.
• Atomic cache write eliminates stale ghosts.




---

4) Routes — wire it to the API

In server/routes/shiftAnalysis.ts (or equivalent), call computeShiftAll in the rebuild path and items path when cache is empty:

// POST /api/analysis/shift/rebuild?date=YYYY-MM-DD
// GET  /api/analysis/shift/items?date=YYYY-MM-DD
// GET  /api/analysis/shift/raw?date=YYYY-MM-DD (existing raw debug OK)

import { computeShiftAll } from '../services/shiftItems';

// In rebuild handler:
const data = await computeShiftAll(date); // overwrites cache inside
res.json({ ok:true, sourceUsed:'live', ...data });

// In items handler:
// 1) try cache; if empty -> computeShiftAll(date) and return 'live'


---

5) Catalog load (already done, re-run if you changed anything)

CATALOG_PATH="/mnt/data/Item and SKU List - Latest" \
tsx server/scripts/catalog_import_from_file.ts


---

6) Backfill week + rebuild cache (5pm→3am)

FROM=2025-10-12; TO=2025-10-23
curl -s -X POST "/api/loyverse/sync?from=$FROM&to=$TO" | jq

for d in $(seq -w 12 23); do
  curl -s -X POST "/api/analysis/shift/rebuild?date=2025-10-$d" \
  | jq -r '"✅ " + .shiftDate + " • " + (.items|length|tostring) + " items (" + .sourceUsed + ")"'
done


---

7) Verify quickly (no guessing)

# 7.1 Raw window rows exist
curl -s "/api/analysis/shift/raw?date=2025-10-23" | jq '{fromISO,toISO,rows:(.rows|length)}'

# 7.2 No UNKNOWN after alias+catalog (ideally 0)
curl -s "/api/analysis/shift/items?date=2025-10-23" \
| jq '[.items[] | select(.name=="UNKNOWN" or .sku==null)] | length'

# 7.3 Burgers sane: sets no longer inflate base burgers
curl -s "/api/analysis/shift/items?date=2025-10-23" \
| jq '[.items[] | select(.category=="burger")] | map({sku,name,qty})'

If you want, run the reconcile script you already have for a hard, per-SKU diff vs POS export.


---

8) Nightly job (after shift ends)

# 03:05 Bangkok — import yesterday, rebuild cache
curl -s -X POST "/api/loyverse/sync?from=$(date -d 'yesterday' +%F)&to=$(date -d 'yesterday' +%F)" >/dev/null
curl -s -X POST "/api/analysis/shift/rebuild?date=$(date -d 'yesterday' +%F)" >/dev/null


---

Notes / gotchas (already handled)

No late receipts: we proved the window is clean; inflation was meals+base overlap.

Modifiers: now stored in analytics_shift_modifier so you can add a “MODIFIER” tab in the UI (exact same table shape as items, minus meat/rolls).

Two analytics systems: make this the source of truth; disable any legacy job that writes different cache tables.

Expired uploads: if you want me to re-audit older days with POS CSVs, re-upload them; the system doesn’t depend on those, it uses the API + catalog.



---